{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6449e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Display settings: do not abbreviate DataFrame output\n",
    "pd.set_option(\"display.max_rows\", None)        # show all rows\n",
    "pd.set_option(\"display.max_columns\", None)     # show all columns\n",
    "pd.set_option(\"display.width\", None)           # don't wrap to fit console width\n",
    "pd.set_option(\"display.max_colwidth\", None)    # don't truncate column contents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e066d4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing responses/cancer/responses_obs0_int3_shuf3_anon_Llama-3.2-3B.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_anon_Qwen3-30B-A3B-Instruct-2507.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_anon_Qwen3-32B.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_anon_Qwen3-4B.csv ...\n",
      "  -> 21 rows -> 21 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_anon_gemini-2.5-flash.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_anon_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_anon_rules_Qwen3-4B.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_anon_rules_gemini-2.5-flash.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_anon_rules_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_anon_rules_steps_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_anon_steps_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_gemini-2.5-flash.csv ...\n",
      "  -> 31 rows -> 31 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_rules_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_rules_steps_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf3_steps_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf5_anon_Llama-3.2-3B.csv ...\n",
      "  -> 50 rows -> 50 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf5_anon_Qwen3-32B.csv ...\n",
      "  -> 50 rows -> 50 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf5_anon_Qwen3-4B.csv ...\n",
      "  -> 50 rows -> 50 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf5_anon_rules_Llama-3.2-3B.csv ...\n",
      "  -> 50 rows -> 50 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf5_anon_rules_Qwen3-32B.csv ...\n",
      "  -> 50 rows -> 50 rows after dedup\n",
      "Processing responses/cancer/responses_obs0_int3_shuf5_anon_rules_Qwen3-4B.csv ...\n",
      "  -> 50 rows -> 50 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_anon_Qwen3-32B.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_anon_gemini-2.5-flash.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_anon_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_anon_rules_gemini-2.5-flash.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_anon_rules_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_anon_rules_steps_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_anon_steps_gemini-2.5-flash.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_anon_steps_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_gemini-2.5-flash.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_gpt-4o-mini-2024-07-18.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_rules_gemini-2.5-flash.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_rules_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_rules_steps_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf3_steps_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf5_anon_Llama-3.2-3B.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf5_anon_Qwen3-32B.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf5_anon_Qwen3-4B.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf5_anon_rules_Llama-3.2-3B.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf5_anon_rules_Qwen3-32B.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int0_shuf5_anon_rules_Qwen3-4B.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_Meta-Llama-3-8B.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_Qwen3-30B-A3B-Instruct-2507.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_Qwen3-32B.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_Qwen3-4B.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_Meta-Llama-3-8B.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_Qwen3-30B-A3B-Instruct-2507.csv ...\n",
      "  -> 10 rows -> 10 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_Qwen3-32B.csv ...\n",
      "  -> 11 rows -> 11 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_Qwen3-4B.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_gemini-2.5-flash.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_gpt-4o-mini-2024-07-18.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_gpt-5-thinking-mini.csv ...\n",
      "  -> 0 rows -> 0 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_rules_Meta-Llama-3-8B.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_rules_Qwen3-30B-A3B-Instruct-2507.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_rules_Qwen3-32B.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_rules_Qwen3-4B.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_rules_gemini-2.5-flash.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_rules_gpt-4o-mini-2024-07-18.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_rules_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_rules_steps_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_rules_steps_gpt-5-mini-2025-08-07.csv ...\n",
      "  -> 0 rows -> 0 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_steps_Qwen3-30B-A3B-Instruct-2507.csv ...\n",
      "  -> 8 rows -> 8 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_steps_Qwen3-32B.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_steps_gemini-2.5-flash.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_anon_steps_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_gedge20_anon_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_gedge20_anon_rules_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_gedge20_anon_rules_steps_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_gedge20_anon_steps_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_gemini-2.5-flash.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_gpt-4.1-mini.csv ...\n",
      "  -> 4 rows -> 4 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_gpt-4o-mini-2024-07-18.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_rules_Meta-Llama-3-8B.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_rules_Qwen3-30B-A3B-Instruct-2507.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_rules_Qwen3-32B.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_rules_Qwen3-4B.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_rules_gemini-2.5-flash.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_rules_gpt-4o-mini-2024-07-18.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_rules_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_rules_steps_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf3_steps_gpt-4o-mini.csv ...\n",
      "  -> 30 rows -> 30 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf5_anon_Llama-3.2-3B.csv ...\n",
      "  -> 50 rows -> 50 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf5_anon_Qwen3-32B.csv ...\n",
      "  -> 50 rows -> 50 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf5_anon_Qwen3-4B.csv ...\n",
      "  -> 50 rows -> 50 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf5_anon_rules_Llama-3.2-3B.csv ...\n",
      "  -> 50 rows -> 50 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf5_anon_rules_Qwen3-32B.csv ...\n",
      "  -> 50 rows -> 50 rows after dedup\n",
      "Processing responses/cancer/responses_obs200_int3_shuf5_anon_rules_Qwen3-4B.csv ...\n",
      "  -> 50 rows -> 50 rows after dedup\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "base = Path(\"responses/cancer\")\n",
    "\n",
    "for csv_path in sorted(base.glob(\"responses*.csv\")):\n",
    "    print(f\"Processing {csv_path} ...\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Only deduplicate files that actually look like model outputs\n",
    "    if \"prompt\" not in df.columns or \"raw_response\" not in df.columns:\n",
    "        print(\"  -> Skipping (missing 'prompt' or 'raw_response').\")\n",
    "        continue\n",
    "\n",
    "    # --- robust valid_flag ---\n",
    "    if \"valid\" in df.columns:\n",
    "        # Turn into strings, strip, and treat a small set as \"true\"\n",
    "        vstr = df[\"valid\"].astype(str).str.strip()\n",
    "        df[\"valid_flag\"] = vstr.isin([\"1\", \"true\", \"True\", \"TRUE\", \"yes\", \"Yes\"])\n",
    "    else:\n",
    "        df[\"valid_flag\"] = False\n",
    "\n",
    "    df[\"valid_flag\"] = df[\"valid_flag\"].astype(int)\n",
    "\n",
    "    # raw_response is \"usable\" if non-null and not just whitespace\n",
    "    df[\"raw_ok\"] = df[\"raw_response\"].notna() & df[\"raw_response\"].astype(str).str.strip().ne(\"\")\n",
    "\n",
    "    # Priority: 3 = valid & raw_ok, 2 = valid only, 1 = raw_ok only, 0 = neither\n",
    "    df[\"priority\"] = df[\"valid_flag\"] * 2 + df[\"raw_ok\"].astype(int)\n",
    "\n",
    "    before = len(df)\n",
    "\n",
    "    # Sort so best row per prompt comes first, then drop duplicates on prompt\n",
    "    df_sorted = df.sort_values([\"prompt\", \"priority\"], ascending=[True, False])\n",
    "    df_nodup = df_sorted.drop_duplicates(subset=[\"prompt\"], keep=\"first\")\n",
    "\n",
    "    # Drop helper columns\n",
    "    df_nodup = df_nodup.drop(columns=[\"valid_flag\", \"raw_ok\", \"priority\"])\n",
    "\n",
    "    after = len(df_nodup)\n",
    "    print(f\"  -> {before} rows -> {after} rows after dedup\")\n",
    "\n",
    "    # Overwrite original file\n",
    "    df_nodup.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "93ff296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responses/cancer/completeness_summary.csv: INCOMPLETE (missing prompt column; missing raw_response column)\n",
      "responses/cancer/eval_summary.csv: INCOMPLETE (missing prompt column; missing raw_response column)\n",
      "responses/cancer/predictions_obs0_int3_ENCO.csv -> rows=1, (ENCO: skipping prompt/raw checks) valid_flags=0 [OK]\n",
      "responses/cancer/predictions_obs2000_int30_ENCO.csv -> rows=1, (ENCO: skipping prompt/raw checks) valid_flags=0 [OK]\n",
      "responses/cancer/predictions_obs200_int0_ENCO.csv -> rows=1, (ENCO: skipping prompt/raw checks) valid_flags=0 [OK]\n",
      "responses/cancer/predictions_obs200_int3_ENCO.csv -> rows=1, (ENCO: skipping prompt/raw checks) valid_flags=0 [OK]\n",
      "responses/cancer/predictions_obs200_int5_ENCO.csv -> rows=1, (ENCO: skipping prompt/raw checks) valid_flags=0 [OK]\n",
      "responses/cancer/predictions_obs500_int5_ENCO.csv -> rows=1, (ENCO: skipping prompt/raw checks) valid_flags=0 [OK]\n",
      "responses/cancer/prompts_obs0_int3_shuf3_anon_gemini-2.5-flash.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/prompts_obs0_int3_shuf3_anon_steps_gemini-2.5-flash.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=29 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_anon_Llama-3.2-3B.csv -> rows=30, prompts=30, raw_responses=13, error_responses=0, valid_flags=3 [INCOMPLETE]\n",
      "responses/cancer/responses_obs0_int3_shuf3_anon_Qwen3-30B-A3B-Instruct-2507.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_anon_Qwen3-32B.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=29 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_anon_Qwen3-4B.csv -> rows=21, prompts=21, raw_responses=21, error_responses=0, valid_flags=3 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_anon_gemini-2.5-flash.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_anon_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_anon_rules_Qwen3-4B.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=0 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_anon_rules_gemini-2.5-flash.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_anon_rules_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_anon_rules_steps_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=29 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_anon_steps_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=27 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_gedge20_anon_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_gemini-2.5-flash.csv -> rows=31, prompts=30, raw_responses=31, error_responses=24, valid_flags=6 [INCOMPLETE]\n",
      "responses/cancer/responses_obs0_int3_shuf3_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_rules_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_rules_steps_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=21 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf3_steps_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=23 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf5_anon_Llama-3.2-3B.csv -> rows=50, prompts=50, raw_responses=10, error_responses=0, valid_flags=1 [INCOMPLETE]\n",
      "responses/cancer/responses_obs0_int3_shuf5_anon_Qwen3-32B.csv -> rows=50, prompts=50, raw_responses=50, error_responses=0, valid_flags=17 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf5_anon_Qwen3-4B.csv -> rows=50, prompts=50, raw_responses=50, error_responses=0, valid_flags=3 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf5_anon_rules_Llama-3.2-3B.csv -> rows=50, prompts=50, raw_responses=2, error_responses=0, valid_flags=0 [INCOMPLETE]\n",
      "responses/cancer/responses_obs0_int3_shuf5_anon_rules_Qwen3-32B.csv -> rows=50, prompts=50, raw_responses=50, error_responses=0, valid_flags=25 [OK]\n",
      "responses/cancer/responses_obs0_int3_shuf5_anon_rules_Qwen3-4B.csv -> rows=50, prompts=50, raw_responses=50, error_responses=0, valid_flags=2 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_anon_Qwen3-32B.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_anon_gemini-2.5-flash.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_anon_gpt-4o-mini.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_anon_rules_gemini-2.5-flash.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_anon_rules_gpt-4o-mini.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_anon_rules_steps_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=28 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_anon_steps_gemini-2.5-flash.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_anon_steps_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_gedge20_anon_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_gemini-2.5-flash.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_gpt-4o-mini-2024-07-18.csv -> rows=10, prompts=10, raw_responses=10, error_responses=9, valid_flags=1 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_gpt-4o-mini.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_rules_gemini-2.5-flash.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_rules_gpt-4o-mini.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_rules_steps_gpt-4o-mini.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf3_steps_gpt-4o-mini.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf5_anon_Llama-3.2-3B.csv -> rows=10, prompts=10, raw_responses=6, error_responses=0, valid_flags=0 [INCOMPLETE]\n",
      "responses/cancer/responses_obs200_int0_shuf5_anon_Qwen3-32B.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf5_anon_Qwen3-4B.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=1 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf5_anon_rules_Llama-3.2-3B.csv -> rows=10, prompts=10, raw_responses=9, error_responses=0, valid_flags=0 [INCOMPLETE]\n",
      "responses/cancer/responses_obs200_int0_shuf5_anon_rules_Qwen3-32B.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int0_shuf5_anon_rules_Qwen3-4B.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=1 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_Meta-Llama-3-8B.csv -> rows=30, prompts=30, raw_responses=0, error_responses=0, valid_flags=0 [INCOMPLETE]\n",
      "responses/cancer/responses_obs200_int3_shuf3_Qwen3-30B-A3B-Instruct-2507.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_Qwen3-32B.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=27 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_Qwen3-4B.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=0 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_Meta-Llama-3-8B.csv -> rows=30, prompts=30, raw_responses=0, error_responses=0, valid_flags=0 [INCOMPLETE]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_Qwen3-30B-A3B-Instruct-2507.csv -> rows=10, prompts=10, raw_responses=10, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_Qwen3-32B.csv -> rows=11, prompts=11, raw_responses=11, error_responses=0, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_Qwen3-4B.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=3 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_gemini-2.5-flash.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_gpt-4o-mini-2024-07-18.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_gpt-5-thinking-mini.csv -> rows=0, prompts=0, raw_responses=0, error_responses=0, valid_flags=0 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_rules_Meta-Llama-3-8B.csv -> rows=30, prompts=30, raw_responses=0, error_responses=0, valid_flags=0 [INCOMPLETE]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_rules_Qwen3-30B-A3B-Instruct-2507.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_rules_Qwen3-32B.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=23 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_rules_Qwen3-4B.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=3 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_rules_gemini-2.5-flash.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_rules_gpt-4o-mini-2024-07-18.csv -> rows=30, prompts=30, raw_responses=30, error_responses=21, valid_flags=9 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_rules_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_rules_steps_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_rules_steps_gpt-5-mini-2025-08-07.csv -> rows=0, prompts=0, raw_responses=0, error_responses=0, valid_flags=0 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_steps_Qwen3-30B-A3B-Instruct-2507.csv -> rows=8, prompts=8, raw_responses=8, error_responses=0, valid_flags=7 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_steps_Qwen3-32B.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_steps_gemini-2.5-flash.csv -> rows=30, prompts=30, raw_responses=30, error_responses=20, valid_flags=10 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_anon_steps_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=29 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_gedge20_anon_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_gedge20_anon_rules_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_gedge20_anon_rules_steps_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_gedge20_anon_steps_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=29 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_gemini-2.5-flash.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_gpt-4.1-mini.csv -> rows=4, prompts=4, raw_responses=4, error_responses=0, valid_flags=4 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_gpt-4o-mini-2024-07-18.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_rules_Meta-Llama-3-8B.csv -> rows=30, prompts=30, raw_responses=0, error_responses=0, valid_flags=0 [INCOMPLETE]\n",
      "responses/cancer/responses_obs200_int3_shuf3_rules_Qwen3-30B-A3B-Instruct-2507.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_rules_Qwen3-32B.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=24 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_rules_Qwen3-4B.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=1 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_rules_gemini-2.5-flash.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_rules_gpt-4o-mini-2024-07-18.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_rules_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=30 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_rules_steps_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=28 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf3_steps_gpt-4o-mini.csv -> rows=30, prompts=30, raw_responses=30, error_responses=0, valid_flags=25 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf5_anon_Llama-3.2-3B.csv -> rows=50, prompts=50, raw_responses=8, error_responses=0, valid_flags=0 [INCOMPLETE]\n",
      "responses/cancer/responses_obs200_int3_shuf5_anon_Qwen3-32B.csv -> rows=50, prompts=50, raw_responses=50, error_responses=0, valid_flags=38 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf5_anon_Qwen3-4B.csv -> rows=50, prompts=50, raw_responses=50, error_responses=0, valid_flags=1 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf5_anon_rules_Llama-3.2-3B.csv -> rows=50, prompts=50, raw_responses=9, error_responses=0, valid_flags=2 [INCOMPLETE]\n",
      "responses/cancer/responses_obs200_int3_shuf5_anon_rules_Qwen3-32B.csv -> rows=50, prompts=50, raw_responses=50, error_responses=0, valid_flags=45 [OK]\n",
      "responses/cancer/responses_obs200_int3_shuf5_anon_rules_Qwen3-4B.csv -> rows=50, prompts=50, raw_responses=50, error_responses=0, valid_flags=4 [OK]\n",
      "\n",
      "=== Completeness Summary ===\n",
      "These files look incomplete:\n",
      "- responses/cancer/completeness_summary.csv: missing prompt column; missing raw_response column\n",
      "- responses/cancer/eval_summary.csv: missing prompt column; missing raw_response column\n",
      "- responses/cancer/responses_obs0_int3_shuf3_anon_Llama-3.2-3B.csv: rows=30, prompts=30, raw_responses=13\n",
      "- responses/cancer/responses_obs0_int3_shuf3_gemini-2.5-flash.csv: rows=31, prompts=30, raw_responses=31\n",
      "- responses/cancer/responses_obs0_int3_shuf5_anon_Llama-3.2-3B.csv: rows=50, prompts=50, raw_responses=10\n",
      "- responses/cancer/responses_obs0_int3_shuf5_anon_rules_Llama-3.2-3B.csv: rows=50, prompts=50, raw_responses=2\n",
      "- responses/cancer/responses_obs200_int0_shuf5_anon_Llama-3.2-3B.csv: rows=10, prompts=10, raw_responses=6\n",
      "- responses/cancer/responses_obs200_int0_shuf5_anon_rules_Llama-3.2-3B.csv: rows=10, prompts=10, raw_responses=9\n",
      "- responses/cancer/responses_obs200_int3_shuf3_Meta-Llama-3-8B.csv: rows=30, prompts=30, raw_responses=0\n",
      "- responses/cancer/responses_obs200_int3_shuf3_anon_Meta-Llama-3-8B.csv: rows=30, prompts=30, raw_responses=0\n",
      "- responses/cancer/responses_obs200_int3_shuf3_anon_rules_Meta-Llama-3-8B.csv: rows=30, prompts=30, raw_responses=0\n",
      "- responses/cancer/responses_obs200_int3_shuf3_rules_Meta-Llama-3-8B.csv: rows=30, prompts=30, raw_responses=0\n",
      "- responses/cancer/responses_obs200_int3_shuf5_anon_Llama-3.2-3B.csv: rows=50, prompts=50, raw_responses=8\n",
      "- responses/cancer/responses_obs200_int3_shuf5_anon_rules_Llama-3.2-3B.csv: rows=50, prompts=50, raw_responses=9\n",
      "\n",
      "Evaluating responses/cancer/predictions_obs0_int3_ENCO.csv\n",
      "\n",
      "Evaluating responses/cancer/predictions_obs2000_int30_ENCO.csv\n",
      "\n",
      "Evaluating responses/cancer/predictions_obs200_int0_ENCO.csv\n",
      "\n",
      "Evaluating responses/cancer/predictions_obs200_int3_ENCO.csv\n",
      "\n",
      "Evaluating responses/cancer/predictions_obs200_int5_ENCO.csv\n",
      "\n",
      "Evaluating responses/cancer/predictions_obs500_int5_ENCO.csv\n",
      "\n",
      "Evaluating responses/cancer/prompts_obs0_int3_shuf3_anon_gemini-2.5-flash.csv\n",
      "\n",
      "Evaluating responses/cancer/prompts_obs0_int3_shuf3_anon_steps_gemini-2.5-flash.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_anon_Qwen3-30B-A3B-Instruct-2507.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_anon_Qwen3-32B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_anon_Qwen3-4B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_anon_gemini-2.5-flash.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_anon_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_anon_rules_Qwen3-4B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_anon_rules_gemini-2.5-flash.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_anon_rules_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_anon_rules_steps_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_anon_steps_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_gedge20_anon_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_rules_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_rules_steps_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf3_steps_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf5_anon_Qwen3-32B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf5_anon_Qwen3-4B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf5_anon_rules_Qwen3-32B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs0_int3_shuf5_anon_rules_Qwen3-4B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_anon_Qwen3-32B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_anon_gemini-2.5-flash.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_anon_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_anon_rules_gemini-2.5-flash.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_anon_rules_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_anon_rules_steps_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_anon_steps_gemini-2.5-flash.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_anon_steps_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_gedge20_anon_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_gemini-2.5-flash.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_gpt-4o-mini-2024-07-18.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_rules_gemini-2.5-flash.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_rules_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_rules_steps_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf3_steps_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf5_anon_Qwen3-32B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf5_anon_Qwen3-4B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf5_anon_rules_Qwen3-32B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int0_shuf5_anon_rules_Qwen3-4B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_Qwen3-30B-A3B-Instruct-2507.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_Qwen3-32B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_Qwen3-4B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_Qwen3-30B-A3B-Instruct-2507.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_Qwen3-32B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_Qwen3-4B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_gemini-2.5-flash.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_gpt-4o-mini-2024-07-18.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_gpt-5-thinking-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_rules_Qwen3-30B-A3B-Instruct-2507.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_rules_Qwen3-32B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_rules_Qwen3-4B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_rules_gemini-2.5-flash.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_rules_gpt-4o-mini-2024-07-18.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_rules_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_rules_steps_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_rules_steps_gpt-5-mini-2025-08-07.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_steps_Qwen3-30B-A3B-Instruct-2507.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_steps_Qwen3-32B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_steps_gemini-2.5-flash.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_anon_steps_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_gedge20_anon_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_gedge20_anon_rules_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_gedge20_anon_rules_steps_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_gedge20_anon_steps_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_gemini-2.5-flash.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_gpt-4.1-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_gpt-4o-mini-2024-07-18.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_rules_Qwen3-30B-A3B-Instruct-2507.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_rules_Qwen3-32B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_rules_Qwen3-4B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_rules_gemini-2.5-flash.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_rules_gpt-4o-mini-2024-07-18.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_rules_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_rules_steps_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf3_steps_gpt-4o-mini.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf5_anon_Qwen3-32B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf5_anon_Qwen3-4B.csv\n",
      "[ERROR] evaluate.py failed on responses/cancer/responses_obs200_int3_shuf5_anon_Qwen3-4B.csv\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/u/chenyuen0103/ENCO/experiments/evaluate.py\", line 579, in <module>\n",
      "    main()\n",
      "  File \"/u/chenyuen0103/ENCO/experiments/evaluate.py\", line 416, in main\n",
      "    met = eval_pair(A_true, A_pred)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/u/chenyuen0103/ENCO/experiments/evaluate.py\", line 240, in eval_pair\n",
      "    raise ValueError(f\"Shape mismatch: true {A_true.shape}, pred {A_pred.shape}\")\n",
      "ValueError: Shape mismatch: true (5, 5), pred (4, 4)\n",
      "\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf5_anon_rules_Qwen3-32B.csv\n",
      "\n",
      "Evaluating responses/cancer/responses_obs200_int3_shuf5_anon_rules_Qwen3-4B.csv\n",
      "\n",
      "Evaluation summary written to: /u/chenyuen0103/ENCO/experiments/responses/cancer/eval_summary.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import json\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "BASE_DIR = Path(\"responses/cancer\")\n",
    "SUMMARY_CSV = BASE_DIR / \"eval_summary.csv\"\n",
    "\n",
    "def parse_given_edges_tag(path: Path):\n",
    "    \"\"\"\n",
    "    Parse given-edges info from filenames like:\n",
    "      ..._gedge20_...\n",
    "    Returns (has_given_edges, given_edge_frac, given_edge_pct)\n",
    "      has_given_edges: 0/1\n",
    "      given_edge_frac: float or None\n",
    "      given_edge_pct:  int or None\n",
    "    \"\"\"\n",
    "    stem = path.stem  # e.g. responses_obs200_int3_shuf3_gedge20_anon_gpt-4o-mini\n",
    "    m = re.search(r\"_gedge(\\d+)\", stem)\n",
    "    if not m:\n",
    "        return 0, None, None\n",
    "    pct = int(m.group(1))\n",
    "    frac = pct / 100.0\n",
    "    return 1, frac, pct\n",
    "\n",
    "def count_nonempty(colname, rows):\n",
    "    return sum(1 for r in rows if (r.get(colname) or \"\").strip())\n",
    "\n",
    "def count_valid_flag(rows):\n",
    "    # valid column is expected to be 1/0 or truthy/falsy\n",
    "    return sum(1 for r in rows if str(r.get(\"valid\", \"\")).strip() in {\"1\", \"true\", \"True\"})\n",
    "\n",
    "def count_error_raw(rows):\n",
    "    # count rows where raw_response contains \"[ERROR]\"\n",
    "    return sum(\n",
    "        1\n",
    "        for r in rows\n",
    "        if \"[ERROR]\" in (r.get(\"raw_response\") or \"\")\n",
    "    )\n",
    "\n",
    "incomplete_files = []\n",
    "complete_files = []\n",
    "file_stats = {}  # file -> dict with n_rows, n_raw, n_valid, n_error\n",
    "\n",
    "if not BASE_DIR.exists():\n",
    "    print(f\"Base directory not found: {BASE_DIR.resolve()}\")\n",
    "else:\n",
    "    for csv_path in sorted(BASE_DIR.rglob(\"*.csv\")):\n",
    "        try:\n",
    "            with csv_path.open(\"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "                reader = csv.DictReader(f)\n",
    "                rows = list(reader)\n",
    "                fieldnames = reader.fieldnames or []\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to read {csv_path}: {e}\")\n",
    "            incomplete_files.append((csv_path, \"read_error\"))\n",
    "            continue\n",
    "\n",
    "        n_rows = len(rows)\n",
    "        has_prompt = \"prompt\" in fieldnames\n",
    "        has_raw = \"raw_response\" in fieldnames\n",
    "\n",
    "        # --------- SPECIAL CASE: ENCO prediction files ---------\n",
    "        # e.g. predictions_obs200_int3_ENCO.csv\n",
    "        is_enco = \"ENCO\" in csv_path.name\n",
    "\n",
    "        if is_enco:\n",
    "            # ENCO files don't have prompt/raw_response; treat them as\n",
    "            # complete as long as they have at least 1 row.\n",
    "            n_prompt = 0\n",
    "            n_raw = 0\n",
    "            n_valid = 0\n",
    "            n_error = 0\n",
    "\n",
    "            complete = n_rows > 0\n",
    "            status = \"OK\" if complete else \"INCOMPLETE\"\n",
    "            print(\n",
    "                f\"{csv_path} -> rows={n_rows}, (ENCO: skipping prompt/raw checks) \"\n",
    "                f\"valid_flags={n_valid} [{status}]\"\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # --------- Normal LLM response files (must have prompt & raw_response) ---------\n",
    "            if not has_prompt or not has_raw:\n",
    "                reason_parts = []\n",
    "                if not has_prompt:\n",
    "                    reason_parts.append(\"missing prompt column\")\n",
    "                if not has_raw:\n",
    "                    reason_parts.append(\"missing raw_response column\")\n",
    "                reason = \"; \".join(reason_parts)\n",
    "                print(f\"{csv_path}: INCOMPLETE ({reason})\")\n",
    "                incomplete_files.append((csv_path, reason))\n",
    "                continue\n",
    "\n",
    "            n_prompt = count_nonempty(\"prompt\", rows)\n",
    "            n_raw = count_nonempty(\"raw_response\", rows)\n",
    "            n_valid = count_valid_flag(rows) if \"valid\" in fieldnames else 0\n",
    "            n_error = count_error_raw(rows)\n",
    "\n",
    "            complete = (n_prompt == n_raw == n_rows)\n",
    "            status = \"OK\" if complete else \"INCOMPLETE\"\n",
    "            print(\n",
    "                f\"{csv_path} -> rows={n_rows}, prompts={n_prompt}, \"\n",
    "                f\"raw_responses={n_raw}, error_responses={n_error}, \"\n",
    "                f\"valid_flags={n_valid} [{status}]\"\n",
    "            )\n",
    "\n",
    "        # --------- Store stats for later use in the summary CSV ---------\n",
    "        file_stats[csv_path] = {\n",
    "            \"n_rows\": n_rows,\n",
    "            \"completed_rows\": n_raw,\n",
    "            \"valid_flag_rows\": n_valid,\n",
    "            \"error_raw_responses\": n_error,\n",
    "        }\n",
    "\n",
    "        if complete:\n",
    "            complete_files.append(csv_path)\n",
    "        else:\n",
    "            reason = f\"rows={n_rows}, prompts={n_prompt}, raw_responses={n_raw}\"\n",
    "            incomplete_files.append((csv_path, reason))\n",
    "\n",
    "    # --------- Delete files with only [ERROR] raw_responses ---------\n",
    "    all_error_files = []\n",
    "    for csv_path_err, stats in list(file_stats.items()):\n",
    "        n_rows_err = stats[\"n_rows\"]\n",
    "        n_error_err = stats[\"error_raw_responses\"]\n",
    "\n",
    "        # For ENCO, n_error_err == 0, so this will never trigger\n",
    "        if n_rows_err > 0 and n_rows_err == n_error_err:\n",
    "            print(f\"[CLEANUP] Deleting {csv_path_err} (all {n_rows_err} raw_responses contain '[ERROR]').\")\n",
    "            all_error_files.append(csv_path_err)\n",
    "\n",
    "            # Remove from complete_files if it was marked complete\n",
    "            if csv_path_err in complete_files:\n",
    "                complete_files.remove(csv_path_err)\n",
    "\n",
    "            # Delete the CSV itself\n",
    "            try:\n",
    "                csv_path_err.unlink()\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "            # Optionally delete any sidecar files created in previous runs\n",
    "            jsonl_path = csv_path_err.with_suffix(\".jsonl\")\n",
    "            summary_path = csv_path_err.with_suffix(csv_path_err.suffix + \".summary.json\")\n",
    "            for sidecar in (jsonl_path, summary_path):\n",
    "                try:\n",
    "                    sidecar.unlink()\n",
    "                except FileNotFoundError:\n",
    "                    pass\n",
    "\n",
    "    # --------- Completeness summary to stdout ---------\n",
    "    print(\"\\n=== Completeness Summary ===\")\n",
    "    if not incomplete_files:\n",
    "        print(\"All CSV files in responses/cancer/ appear complete.\")\n",
    "    else:\n",
    "        print(\"These files look incomplete:\")\n",
    "        for path, reason in incomplete_files:\n",
    "            print(f\"- {path}: {reason}\")\n",
    "\n",
    "    # --------- Run evaluate.py on complete files & collect metrics ---------\n",
    "    summary_rows = []\n",
    "\n",
    "    for csv_path in complete_files:\n",
    "        print(f\"\\nEvaluating {csv_path}\")\n",
    "        proc = subprocess.run(\n",
    "            [\"python\", \"evaluate.py\", \"--csv\", str(csv_path)],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "        )\n",
    "        if proc.returncode != 0:\n",
    "            print(f\"[ERROR] evaluate.py failed on {csv_path}\")\n",
    "            print(proc.stdout)\n",
    "            print(proc.stderr)\n",
    "            continue\n",
    "\n",
    "        # evaluate.py should have created <file>.summary.json\n",
    "        summary_path = csv_path.with_suffix(csv_path.suffix + \".summary.json\")\n",
    "        if not summary_path.exists():\n",
    "            print(f\"[WARN] Summary JSON not found for {csv_path}: {summary_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with summary_path.open(\"r\", encoding=\"utf-8\") as f_sum:\n",
    "                metrics = json.load(f_sum)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to read summary JSON for {csv_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Build one combined row: file name + completeness stats + eval metrics\n",
    "        # Build one combined row: file name + completeness stats + eval metrics\n",
    "        base_stats = file_stats[csv_path]\n",
    "\n",
    "        # Rename potentially confusing keys from evaluate.py\n",
    "        metrics[\"eval_num_rows\"] = metrics.pop(\"num_rows\", None)\n",
    "        metrics[\"eval_valid_rows\"] = metrics.pop(\"valid_rows\", None)\n",
    "\n",
    "        # Decode given-edges info from filename\n",
    "        has_given_edges, given_edge_frac, given_edge_pct = parse_given_edges_tag(csv_path)\n",
    "\n",
    "        row = {\n",
    "            \"file\": str(csv_path),\n",
    "            \"num_rows\": base_stats[\"n_rows\"],\n",
    "            \"completed\": base_stats[\"completed_rows\"],        # count(raw_response nonempty)\n",
    "            \"valid\": base_stats[\"valid_flag_rows\"],           # from 'valid' column\n",
    "            \"error_raw_responses\": base_stats[\"error_raw_responses\"],  # rows with \"[ERROR]\" in raw_response\n",
    "\n",
    "            # new columns:\n",
    "            \"given_edges\": has_given_edges,       # 0/1 flag\n",
    "            \"given_edge_frac\": given_edge_frac,   # e.g. 0.2 for _gedge20\n",
    "            \"given_edge_pct\": given_edge_pct,     # e.g. 20 for _gedge20\n",
    "        }\n",
    "        row.update(metrics)\n",
    "\n",
    "        summary_rows.append(row)\n",
    "\n",
    "\n",
    "    # --------- Write global metrics summary CSV ---------\n",
    "    if summary_rows:\n",
    "        SUMMARY_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "        # Collect union of all keys in case some metrics differ\n",
    "        all_keys = []\n",
    "        for r in summary_rows:\n",
    "            for k in r.keys():\n",
    "                if k not in all_keys:\n",
    "                    all_keys.append(k)\n",
    "\n",
    "        with SUMMARY_CSV.open(\"w\", encoding=\"utf-8\", newline=\"\") as f_out:\n",
    "            writer = csv.DictWriter(f_out, fieldnames=all_keys)\n",
    "            writer.writeheader()\n",
    "            for row in summary_rows:\n",
    "                writer.writerow(row)\n",
    "        print(f\"\\nEvaluation summary written to: {SUMMARY_CSV.resolve()}\")\n",
    "    else:\n",
    "        print(\"\\nNo complete files were successfully evaluated; no summary CSV written.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "6c625344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>num_pred_edges</th>\n",
       "      <th>avg_f1</th>\n",
       "      <th>avg_shd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>responses/cancer/responses_obs200_int3_shuf3_anon_rules_steps_gpt-4o-mini.csv</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.614153</td>\n",
       "      <td>3.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>responses/cancer/responses_obs200_int0_shuf3_anon_rules_steps_gpt-4o-mini.csv</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>0.594033</td>\n",
       "      <td>3.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>responses/cancer/responses_obs200_int3_shuf3_gedge20_anon_rules_steps_gpt-4o-mini.csv</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>0.523651</td>\n",
       "      <td>3.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>responses/cancer/responses_obs0_int3_shuf3_anon_rules_steps_gpt-4o-mini.csv</td>\n",
       "      <td>5.793103</td>\n",
       "      <td>0.516652</td>\n",
       "      <td>4.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>responses/cancer/responses_obs200_int3_shuf3_anon_rules_steps_gpt-5-mini-2025-08-07.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       file  \\\n",
       "63            responses/cancer/responses_obs200_int3_shuf3_anon_rules_steps_gpt-4o-mini.csv   \n",
       "32            responses/cancer/responses_obs200_int0_shuf3_anon_rules_steps_gpt-4o-mini.csv   \n",
       "71    responses/cancer/responses_obs200_int3_shuf3_gedge20_anon_rules_steps_gpt-4o-mini.csv   \n",
       "16              responses/cancer/responses_obs0_int3_shuf3_anon_rules_steps_gpt-4o-mini.csv   \n",
       "64  responses/cancer/responses_obs200_int3_shuf3_anon_rules_steps_gpt-5-mini-2025-08-07.csv   \n",
       "\n",
       "    num_pred_edges    avg_f1   avg_shd  \n",
       "63        4.000000  0.614153  3.133333  \n",
       "32        3.714286  0.594033  3.285714  \n",
       "71        2.766667  0.523651  3.166667  \n",
       "16        5.793103  0.516652  4.758621  \n",
       "64             NaN       NaN  0.000000  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('responses/cancer/eval_summary.csv')\n",
    "mask = (\n",
    "    # df['file'].str.contains('steps') &\n",
    "    # df['file'].str.contains('obs200_int3_shuf3_anon') &\n",
    "    # df['file'].str.contains('responses') &\n",
    "    df['file'].str.contains('_anon_rules_steps_gpt', case=False)\n",
    "    # & ~df['file'].str.contains('anon')\n",
    "    # & (df['valid'].astype(int) == 0)\n",
    ")\n",
    "# df[mask][['file', 'num_rows','error_raw_responses','valid', 'avg_f1', 'avg_shd']].sort_values('avg_f1', ascending=False)\n",
    "df[mask].sort_values('avg_f1', ascending=False)[[\"file\",\"num_pred_edges\",\"avg_f1\",\"avg_shd\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "03178394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[ht!]\n",
      "\\centering\n",
      "\\setlength{\\tabcolsep}{6pt}\n",
      "\\caption{Causal discovery performance on the \\textit{Cancer} causal graph. The variable names are anonymized.}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{lcccccc}\n",
      "\\toprule\n",
      " & \\multicolumn{2}{c}{\\textbf{Obs. 200, Inter. 3}} & \\multicolumn{2}{c}{\\textbf{Obs. 200, Inter. 0}} & \\multicolumn{2}{c}{\\textbf{Obs. 0, Inter. 3}} \\\\\n",
      "\\cmidrule(lr){2-3}\\cmidrule(lr){4-5}\\cmidrule(lr){6-7}\n",
      "\\textbf{Method} & \\textbf{SHD}~$\\downarrow$ & \\textbf{F1}~$\\uparrow$ & \\textbf{SHD}~$\\downarrow$ & \\textbf{F1}~$\\uparrow$ & \\textbf{SHD}~$\\downarrow$ & \\textbf{F1}~$\\uparrow$ \\\\\n",
      "\\midrule\n",
      "\\multicolumn{7}{l}{\\textbf{\\textit{Pure Causal Discovery Method}}} \\\\\n",
      "ENCO & 7.00 &  & 4.00 &  & 9.00 & 0.18 \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "\\multicolumn{7}{l}{\\textbf{\\textit{Zero-Shot LLMs}}} \\\\\n",
      "Qwen3-30B-A3B-Instruct-2507 & 3.60 & 0.63 &  &  & 4.37 & 0.69 \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "Qwen3-32B & 5.20 & 0.39 & 4.00 & 0.53 & 4.52 & 0.52 \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "Gemini-2.5-Flash & 5.30 & 0.37 & 6.20 & 0.35 & 6.47 & 0.34 \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "gpt-4o-mini & 6.43 & 0.45 & 7.70 & 0.42 & 5.77 & 0.42 \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "\\multicolumn{7}{l}{\\textbf{\\textit{Zero-Shot LLMs + Causality Rules}}} \\\\\n",
      "Qwen3-30B-A3B-Instruct-2507 & 3.90 & 0.51 &  &  &  &  \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "Qwen3-32B & 4.70 & 0.45 & 4.30 & 0.48 & 4.24 & 0.54 \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "Gemini-2.5-Flash & 5.77 & 0.36 & 6.70 & 0.36 & 5.63 & 0.36 \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "gpt-4o-mini & 6.17 & 0.47 & 5.80 & 0.48 & 5.80 & 0.47 \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "\\multicolumn{7}{l}{\\textbf{\\textit{Zero-Shot LLMs + CD Steps}}} \\\\\n",
      "Qwen3-30B-A3B-Instruct-2507 & 3.14 & 0.67 &  &  &  &  \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "Qwen3-32B & 4.93 & 0.45 &  &  &  &  \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "Gemini-2.5-Flash & 5.90 & 0.42 & 5.90 & 0.47 & 5.79 & 0.40 \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "gpt-4o-mini & 3.90 & 0.55 & 2.97 & 0.63 & 4.89 & 0.51 \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "\\multicolumn{7}{l}{\\textbf{\\textit{Zero-Shot LLMs + Causality Rules + CD Steps}}} \\\\\n",
      "gpt-4o-mini & 3.13 & 0.61 & 3.29 & 0.59 & 4.76 & 0.52 \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "\\multicolumn{7}{l}{\\textbf{\\textit{Zero-Shot LLMs + Given One Edge}}} \\\\\n",
      "gpt-4o-mini & 2.97 & 0.41 & 3.00 & 0.40 & 3.00 & 0.40 \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table*}\n",
      "\\begin{table*}[ht!]\n",
      "\\centering\n",
      "\\setlength{\\tabcolsep}{6pt}\n",
      "\\caption{Valid adjacency extraction ratio for each method and data setting on the \\textit{Cancer} graph.}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{lccc}\n",
      "\\toprule\n",
      " & \\textbf{Obs. 200, Inter. 3} & \\textbf{Obs. 200, Inter. 0} & \\textbf{Obs. 0, Inter. 3} \\\\\n",
      "\\midrule\n",
      "\\multicolumn{4}{l}{\\textbf{\\textit{Pure Causal Discovery Method}}} \\\\\n",
      "ENCO & $\\frac{0}{1}$ & $\\frac{0}{1}$ & $\\frac{0}{1}$ \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "\\multicolumn{4}{l}{\\textbf{\\textit{Zero-Shot LLMs}}} \\\\\n",
      "Qwen3-30B-A3B-Instruct-2507 & $\\frac{10}{10}$ &  & $\\frac{30}{30}$ \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "Qwen3-32B & $\\frac{10}{11}$ & $\\frac{10}{10}$ & $\\frac{29}{30}$ \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "Gemini-2.5-Flash & $\\frac{30}{30}$ & $\\frac{10}{10}$ & $\\frac{30}{30}$ \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "gpt-4o-mini & $\\frac{30}{30}$ & $\\frac{10}{10}$ & $\\frac{30}{30}$ \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "\\multicolumn{4}{l}{\\textbf{\\textit{Zero-Shot LLMs + Causality Rules}}} \\\\\n",
      "Qwen3-30B-A3B-Instruct-2507 & $\\frac{30}{30}$ &  &  \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "Qwen3-32B & $\\frac{23}{30}$ & $\\frac{10}{10}$ & $\\frac{25}{50}$ \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "Gemini-2.5-Flash & $\\frac{30}{30}$ & $\\frac{10}{10}$ & $\\frac{30}{30}$ \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "gpt-4o-mini & $\\frac{30}{30}$ & $\\frac{10}{10}$ & $\\frac{30}{30}$ \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "\\multicolumn{4}{l}{\\textbf{\\textit{Zero-Shot LLMs + CD Steps}}} \\\\\n",
      "Qwen3-30B-A3B-Instruct-2507 & $\\frac{7}{8}$ &  &  \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "Qwen3-32B & $\\frac{30}{30}$ &  &  \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "Gemini-2.5-Flash & $\\frac{10}{30}$ & $\\frac{10}{10}$ & $\\frac{29}{30}$ \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "gpt-4o-mini & $\\frac{29}{30}$ & $\\frac{30}{30}$ & $\\frac{27}{30}$ \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "\\multicolumn{4}{l}{\\textbf{\\textit{Zero-Shot LLMs + Causality Rules + CD Steps}}} \\\\\n",
      "gpt-4o-mini & $\\frac{30}{30}$ & $\\frac{28}{30}$ & $\\frac{29}{30}$ \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "\\multicolumn{4}{l}{\\textbf{\\textit{Zero-Shot LLMs + Given One Edge}}} \\\\\n",
      "gpt-4o-mini & $\\frac{30}{30}$ & $\\frac{30}{30}$ & $\\frac{30}{30}$ \\\\\n",
      "\\addlinespace[0.8ex]\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "EVAL_SUMMARY = Path(\"responses/cancer/eval_summary.csv\")\n",
    "\n",
    "df = pd.read_csv(EVAL_SUMMARY)\n",
    "df = df[~df['file'].str.contains('4B', case=False) &\n",
    "        ~df['file'].str.contains('2024-07-18', case=False)]\n",
    "\n",
    "# --- 0. Keep only anon LLM runs + ENCO baseline --------------------\n",
    "file_str = df[\"file\"].astype(str)\n",
    "is_anon = file_str.str.contains(\"_anon\", regex=False)\n",
    "is_enco = file_str.str.contains(\"ENCO\", regex=False)  # non-anon ENCO runs\n",
    "df = df[is_anon | is_enco].reset_index(drop=True)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def detect_variant(path_str: str) -> str:\n",
    "    name = Path(path_str).name.lower()\n",
    "    if \"rules_steps\" in name:\n",
    "        return \"rules_steps\"\n",
    "    if \"rules\" in name:\n",
    "        return \"rules\"\n",
    "    if \"steps\" in name:\n",
    "        return \"steps\"\n",
    "    return \"base\"\n",
    "\n",
    "df[\"variant\"] = df[\"file\"].astype(str).apply(detect_variant)\n",
    "\n",
    "# Make life easier: ensure 'valid' exists & integer\n",
    "if \"valid\" in df.columns:\n",
    "    df[\"valid\"] = df[\"valid\"].fillna(0).astype(int)\n",
    "else:\n",
    "    df[\"valid\"] = 0\n",
    "\n",
    "\n",
    "# --- 2. Metric lookup helpers --------------------------------------\n",
    "\n",
    "def lookup_metrics(setting_tags, model_tag,\n",
    "                   variant=None,\n",
    "                   min_valid=1,\n",
    "                   given_edge_count=None):\n",
    "    \"\"\"\n",
    "    setting_tags: list like [\"obs200_int3\"]\n",
    "    model_tag:    e.g. \"gpt-4o-mini\" or \"ENCO\"\n",
    "    variant:      one of {\"base\", \"rules\", \"steps\", \"rules_steps\"} or None\n",
    "    given_edge_count: if not None, require df['given_edge_count'] == this value\n",
    "    \"\"\"\n",
    "    m = df[\"file\"].astype(str).str.contains(setting_tags[0], regex=False)\n",
    "    for s in setting_tags[1:]:\n",
    "        m &= df[\"file\"].astype(str).str.contains(s, regex=False)\n",
    "\n",
    "    # model name constraint\n",
    "    m &= df[\"file\"].astype(str).str.contains(model_tag, regex=False)\n",
    "\n",
    "    # only apply valid filter if requested\n",
    "    if min_valid > 0:\n",
    "        m &= df[\"valid\"] >= min_valid\n",
    "\n",
    "    # variant constraint (base / rules / steps / rules_steps)\n",
    "    if variant is not None:\n",
    "        m &= (df[\"variant\"] == variant)\n",
    "\n",
    "    # given-edge constraint\n",
    "    if given_edge_count is not None and \"given_edge_count\" in df.columns:\n",
    "        m &= (df[\"given_edge_count\"] == given_edge_count)\n",
    "\n",
    "    subset = df[m]\n",
    "    if subset.empty:\n",
    "        return None, None\n",
    "\n",
    "    row = subset.iloc[0]   # or subset.mean() if you prefer\n",
    "    return row[\"avg_f1\"], row[\"avg_shd\"]\n",
    "\n",
    "\n",
    "def fmt(x, ndigits=2):\n",
    "    if x is None or (isinstance(x, float) and (math.isnan(x) or math.isinf(x))):\n",
    "        return \"\"\n",
    "    return f\"{x:.{ndigits}f}\"\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Settings (Obs/Inter combinations)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "SETTINGS = {\n",
    "    \"O200_I3\": [\"obs200_int3\"],\n",
    "    \"O200_I0\": [\"obs200_int0\"],\n",
    "    \"O0_I3\":   [\"obs0_int3\"],\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. Extract model tags from filenames (LLMs only; ENCO is special)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def extract_model_tag(path_str: str) -> str:\n",
    "    \"\"\"Get the model part from a path, e.g.\n",
    "       '...responses_obs0_int3_shuf3_anon_Qwen3-32B.csv' -> 'Qwen3-32B'\n",
    "       '...predictions_obs200_int3_ENCO.csv'             -> 'ENCO'\n",
    "    \"\"\"\n",
    "    stem = Path(path_str).stem    # e.g. 'responses_obs0_int3_shuf3_anon_Qwen3-32B'\n",
    "    parts = stem.split(\"_\")\n",
    "    return parts[-1]\n",
    "\n",
    "# Only look at response files for LLM models (ENCO is in predictions files)\n",
    "mask_llm = df[\"file\"].str.contains(\"responses\", regex=False) & \\\n",
    "           ~df[\"file\"].str.contains(\"ENCO\", regex=False)\n",
    "df_models = df[mask_llm].copy()\n",
    "df_models[\"model\"] = df_models[\"file\"].apply(extract_model_tag)\n",
    "\n",
    "all_models = sorted(df_models[\"model\"].unique())\n",
    "# print(\"Detected LLM models:\", all_models)\n",
    "\n",
    "llm_models = all_models  # ENCO handled separately\n",
    "\n",
    "PRETTY_NAME = {\n",
    "    \"gemini-2.5-flash\": \"Gemini-2.5-Flash\",\n",
    "    # add others if you care; fall back to tag itself\n",
    "}\n",
    "def pretty_model_name(model_tag: str) -> str:\n",
    "    return PRETTY_NAME.get(model_tag, model_tag)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5. Variant blocks (sections)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "VARIANTS = [\n",
    "    (\"base\",        r\"\\multicolumn{7}{l}{\\textbf{\\textit{Zero-Shot LLMs}}} \\\\\"),\n",
    "    (\"rules\",       r\"\\multicolumn{7}{l}{\\textbf{\\textit{Zero-Shot LLMs + Causality Rules}}} \\\\\"),\n",
    "    (\"steps\",       r\"\\multicolumn{7}{l}{\\textbf{\\textit{Zero-Shot LLMs + CD Steps}}} \\\\\"),\n",
    "    (\"rules_steps\", r\"\\multicolumn{7}{l}{\\textbf{\\textit{Zero-Shot LLMs + Causality Rules + CD Steps}}} \\\\\"),\n",
    "]\n",
    "\n",
    "ROWS = []\n",
    "\n",
    "# 5.a ENCO (pure causal discovery method, non-anon predictions_*.csv)\n",
    "ROWS.append({\n",
    "    \"section\": r\"\\multicolumn{7}{l}{\\textbf{\\textit{Pure Causal Discovery Method}}} \\\\\",\n",
    "    \"label\":   \"ENCO\",\n",
    "    \"model_tag\": \"ENCO\",\n",
    "    \"variant\": \"base\",\n",
    "    \"given_edge_count\": None,   # no given-edge prior\n",
    "})\n",
    "\n",
    "# 5.b LLM rows for each variant + model\n",
    "for variant_key, section_header in VARIANTS:\n",
    "    first_in_section = True\n",
    "    for model_tag in llm_models:\n",
    "        ROWS.append({\n",
    "            \"section\":   section_header if first_in_section else None,\n",
    "            \"label\":     pretty_model_name(model_tag),\n",
    "            \"model_tag\": model_tag,\n",
    "            \"variant\":   variant_key,\n",
    "            \"given_edge_count\": None,   # normal zero-shot / rules / steps runs\n",
    "        })\n",
    "        first_in_section = False\n",
    "\n",
    "# 5.c NEW: Zero-Shot LLMs + Given One Edge\n",
    "# pick models that have given_edge_count == 1 somewhere\n",
    "if \"given_edge_count\" in df.columns:\n",
    "    mask_given = (\n",
    "        (df[\"given_edge_count\"] == 1) &\n",
    "        df[\"file\"].str.contains(\"responses\", regex=False) &\n",
    "        ~df[\"file\"].str.contains(\"ENCO\", regex=False)\n",
    "    )\n",
    "    df_given = df[mask_given].copy()\n",
    "    given_models = sorted(df_given[\"file\"].apply(extract_model_tag).unique())\n",
    "else:\n",
    "    given_models = []\n",
    "\n",
    "first_in_section = True\n",
    "for model_tag in given_models:\n",
    "    ROWS.append({\n",
    "        \"section\": r\"\\multicolumn{7}{l}{\\textbf{\\textit{Zero-Shot LLMs + Given One Edge}}} \\\\\"\n",
    "                   if first_in_section else None,\n",
    "        \"label\":   pretty_model_name(model_tag),\n",
    "        \"model_tag\": model_tag,\n",
    "        \"variant\": \"base\",          # assume these are base + given-edge\n",
    "        \"given_edge_count\": 1,      # key for filtering in lookup_metrics\n",
    "    })\n",
    "    first_in_section = False\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6. Build LaTeX lines (F1 / SHD table)\n",
    "# -------------------------------------------------------------------\n",
    "lines = []\n",
    "\n",
    "lines.append(r\"\\begin{table*}[ht!]\")\n",
    "lines.append(r\"\\centering\")\n",
    "lines.append(r\"\\setlength{\\tabcolsep}{6pt}\")\n",
    "lines.append(r\"\\caption{Causal discovery performance on the \\textit{Cancer} causal graph. The variable names are anonymized.}\")\n",
    "lines.append(r\"\\resizebox{\\textwidth}{!}{%\")\n",
    "lines.append(r\"\\begin{tabular}{lcccccc}\")\n",
    "lines.append(r\"\\toprule\")\n",
    "lines.append(\n",
    "    r\" & \\multicolumn{2}{c}{\\textbf{Obs. 200, Inter. 3}}\"\n",
    "    r\" & \\multicolumn{2}{c}{\\textbf{Obs. 200, Inter. 0}}\"\n",
    "    r\" & \\multicolumn{2}{c}{\\textbf{Obs. 0, Inter. 3}} \\\\\"\n",
    ")\n",
    "lines.append(r\"\\cmidrule(lr){2-3}\\cmidrule(lr){4-5}\\cmidrule(lr){6-7}\")\n",
    "lines.append(\n",
    "    r\"\\textbf{Method} & \\textbf{SHD}~$\\downarrow$ & \\textbf{F1}~$\\uparrow$\"\n",
    "    r\" & \\textbf{SHD}~$\\downarrow$ & \\textbf{F1}~$\\uparrow$\"\n",
    "    r\" & \\textbf{SHD}~$\\downarrow$ & \\textbf{F1}~$\\uparrow$ \\\\\"\n",
    ")\n",
    "\n",
    "lines.append(r\"\\midrule\")\n",
    "\n",
    "for rowdef in ROWS:\n",
    "    # Optional section header\n",
    "    if rowdef.get(\"section\"):\n",
    "        lines.append(rowdef[\"section\"])\n",
    "\n",
    "    label       = rowdef[\"label\"]\n",
    "    model_tag   = rowdef[\"model_tag\"]\n",
    "    variant_key = rowdef[\"variant\"]\n",
    "    given_edge_count = rowdef.get(\"given_edge_count\", None)\n",
    "\n",
    "    # ENCO: don't require valid>=1, and ignore variant filter\n",
    "    is_enco = (model_tag == \"ENCO\")\n",
    "    min_valid = 0 if is_enco else 1\n",
    "    variant_for_lookup = None if is_enco else variant_key\n",
    "\n",
    "    cells = []\n",
    "    for key, setting_subs in SETTINGS.items():\n",
    "        f1, shd = lookup_metrics(\n",
    "            setting_subs,\n",
    "            model_tag=model_tag,\n",
    "            variant=variant_for_lookup,\n",
    "            min_valid=min_valid,\n",
    "            given_edge_count=given_edge_count,\n",
    "        )\n",
    "        cells.append(fmt(f1))\n",
    "        cells.append(fmt(shd, ndigits=2))\n",
    "\n",
    "    # If *all* entries for this row are empty, skip the row entirely\n",
    "    if all(c == \"\" for c in cells):\n",
    "        continue\n",
    "\n",
    "    row_tex = (\n",
    "        f\"{label} & {cells[1]} & {cells[0]} & \"\n",
    "        f\"{cells[3]} & {cells[2]} & {cells[5]} & {cells[4]} \\\\\\\\\"\n",
    "    )\n",
    "\n",
    "    lines.append(row_tex)\n",
    "    lines.append(r\"\\addlinespace[0.8ex]\")\n",
    "\n",
    "lines.append(r\"\\bottomrule\")\n",
    "lines.append(r\"\\end{tabular}\")\n",
    "lines.append(r\"}\")\n",
    "lines.append(r\"\\end{table*}\")\n",
    "\n",
    "latex_table = \"\\n\".join(lines)\n",
    "print(latex_table)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 7. Valid-ratio table, same sections (including Given One Edge)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def lookup_valid_counts(setting_tags, model_tag,\n",
    "                        variant=None,\n",
    "                        min_rows=1,\n",
    "                        given_edge_count=None):\n",
    "    \"\"\"\n",
    "    Returns (valid, num_rows) or (None, None) if not found.\n",
    "    \"\"\"\n",
    "    m = df[\"file\"].astype(str).str.contains(setting_tags[0], regex=False)\n",
    "    for s in setting_tags[1:]:\n",
    "        m &= df[\"file\"].astype(str).str.contains(s, regex=False)\n",
    "\n",
    "    # constrain to this model\n",
    "    m &= df[\"file\"].astype(str).str.contains(model_tag, regex=False)\n",
    "\n",
    "    # constrain to variant if given\n",
    "    if variant is not None:\n",
    "        m &= (df[\"variant\"] == variant)\n",
    "\n",
    "    # constrain to given_edge_count if given\n",
    "    if given_edge_count is not None and \"given_edge_count\" in df.columns:\n",
    "        m &= (df[\"given_edge_count\"] == given_edge_count)\n",
    "\n",
    "    subset = df[m]\n",
    "    if subset.empty:\n",
    "        return None, None\n",
    "\n",
    "    row = subset.iloc[0]\n",
    "    num_rows = row.get(\"num_rows\", 0)\n",
    "    valid    = row.get(\"valid\", 0)\n",
    "\n",
    "    if not num_rows or num_rows < min_rows:\n",
    "        return None, None\n",
    "\n",
    "    return int(valid), int(num_rows)\n",
    "\n",
    "\n",
    "valid_lines = []\n",
    "\n",
    "valid_lines.append(r\"\\begin{table*}[ht!]\")\n",
    "valid_lines.append(r\"\\centering\")\n",
    "valid_lines.append(r\"\\setlength{\\tabcolsep}{6pt}\")\n",
    "valid_lines.append(\n",
    "    r\"\\caption{Valid adjacency extraction ratio for each method and data setting on the \\textit{Cancer} graph.}\"\n",
    ")\n",
    "valid_lines.append(r\"\\resizebox{\\textwidth}{!}{%\")\n",
    "valid_lines.append(r\"\\begin{tabular}{lccc}\")\n",
    "valid_lines.append(r\"\\toprule\")\n",
    "valid_lines.append(\n",
    "    r\" & \\textbf{Obs. 200, Inter. 3}\"\n",
    "    r\" & \\textbf{Obs. 200, Inter. 0}\"\n",
    "    r\" & \\textbf{Obs. 0, Inter. 3} \\\\\"\n",
    ")\n",
    "valid_lines.append(r\"\\midrule\")\n",
    "\n",
    "for rowdef in ROWS:\n",
    "    # Optional section header  adapt from 7 columns to 4\n",
    "    if rowdef.get(\"section\"):\n",
    "        sec = rowdef[\"section\"]\n",
    "        sec = sec.replace(r\"\\multicolumn{7}\", r\"\\multicolumn{4}\")\n",
    "        valid_lines.append(sec)\n",
    "\n",
    "    label       = rowdef[\"label\"]\n",
    "    model_tag   = rowdef[\"model_tag\"]\n",
    "    variant_key = rowdef[\"variant\"]\n",
    "    given_edge_count = rowdef.get(\"given_edge_count\", None)\n",
    "\n",
    "    cells = []\n",
    "    for key, setting_subs in SETTINGS.items():\n",
    "        valid_count, num_rows = lookup_valid_counts(\n",
    "            setting_subs,\n",
    "            model_tag=model_tag,\n",
    "            variant=variant_key if model_tag != \"ENCO\" else None,\n",
    "            given_edge_count=given_edge_count,\n",
    "        )\n",
    "\n",
    "        if valid_count is None or num_rows is None:\n",
    "            cells.append(\"\")  # empty cell\n",
    "        else:\n",
    "            cells.append(rf\"$\\frac{{{valid_count}}}{{{num_rows}}}$\")\n",
    "\n",
    "    # Skip row entirely if ALL settings are empty\n",
    "    if all(c == \"\" for c in cells):\n",
    "        continue\n",
    "\n",
    "    row_tex = f\"{label} & {cells[0]} & {cells[1]} & {cells[2]} \\\\\\\\\"\n",
    "    valid_lines.append(row_tex)\n",
    "    valid_lines.append(r\"\\addlinespace[0.8ex]\")\n",
    "\n",
    "valid_lines.append(r\"\\bottomrule\")\n",
    "valid_lines.append(r\"\\end{tabular}\")\n",
    "valid_lines.append(r\"}\")\n",
    "valid_lines.append(r\"\\end{table*}\")\n",
    "\n",
    "latex_valid_table = \"\\n\".join(valid_lines)\n",
    "print(latex_valid_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "3e648f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "sys.path.append(\"../\")\n",
    "from causal_graphs.graph_real_world import load_graph_file\n",
    "from causal_graphs.graph_visualization import visualize_graph\n",
    "import matplotlib.pyplot as plt\n",
    "# ---------------------------------------------------------------------\n",
    "# 1. Load the cancer graph\n",
    "# ---------------------------------------------------------------------\n",
    "bif_path = Path(\"../causal_graphs/real_data/small_graphs/cancer.bif\")\n",
    "graph = load_graph_file(str(bif_path))\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2. Build a NetworkX graph with integer nodes (0..n-1)\n",
    "#    so we can reuse the same layout but change labels.\n",
    "# ---------------------------------------------------------------------\n",
    "G = nx.DiGraph()\n",
    "n = len(graph.variables)\n",
    "\n",
    "# Nodes are integers, but we keep two separate label dicts:\n",
    "labels_orig = {}\n",
    "labels_anon = {}\n",
    "\n",
    "for i, v in enumerate(graph.variables):\n",
    "    G.add_node(i)\n",
    "    labels_orig[i] = v.name        # original variable name\n",
    "    labels_anon[i] = f\"X{i+1}\"     # anonymized name\n",
    "\n",
    "# Add directed edges from the CausalDAG\n",
    "for (u_idx, v_idx) in graph.edges.tolist():\n",
    "    G.add_edge(u_idx, v_idx)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3. Compute a single layout (Graphviz) and reuse for both panels\n",
    "# ---------------------------------------------------------------------\n",
    "pos = graphviz_layout(G, prog=\"dot\")  # requires graphviz + pydot\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4. Plot side-by-side: original (left) and anonymized (right)\n",
    "# ---------------------------------------------------------------------\n",
    "figsize = max(3, n ** 0.7)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(2 * figsize, figsize))\n",
    "\n",
    "# Common draw kwargs to mimic your existing style\n",
    "draw_kwargs = dict(\n",
    "    arrows=True,\n",
    "    node_color=\"lightgrey\",\n",
    "    edgecolors=\"black\",\n",
    "    node_size=600,\n",
    "    arrowstyle=\"-|>\",\n",
    "    arrowsize=16,\n",
    ")\n",
    "\n",
    "# Left: original names\n",
    "ax = axes[1]\n",
    "nx.draw(G, pos, ax=ax, with_labels=False, **draw_kwargs)\n",
    "nx.draw_networkx_labels(G, pos, labels=labels_orig, font_weight=\"bold\", ax=ax)\n",
    "ax.set_title(\"Cancer graph (original names)\")\n",
    "ax.set_axis_off()\n",
    "ax.margins(0.2)  # <<< add padding inside axes\n",
    "# Right: anonymized names\n",
    "ax = axes[0]\n",
    "nx.draw(G, pos, ax=ax, with_labels=False, **draw_kwargs)\n",
    "nx.draw_networkx_labels(G, pos, labels=labels_anon, font_weight=\"bold\", ax=ax)\n",
    "ax.set_title(\"Cancer graph (anonymized)\")\n",
    "ax.set_axis_off()\n",
    "ax.margins(0.2)\n",
    "plt.tight_layout(pad=1.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"cancer_graph_original_vs_anon.pdf\", bbox_inches=\"tight\", transparent=True)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "c3a571db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = pd.read_csv(\"responses/cancer/responses_obs200_int3_shuf3_anon_Qwen3-32B.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "fea8e8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check['prediction'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a544c37d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
